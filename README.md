# Projeto: Webscraping para AnÃ¡lise de Mercado
Este projeto foi desenvolvido para realizar uma anÃ¡lise de mercado detalhada de tÃªnis esportivos utilizando webscraping. Ele captura dados de um marketplace popular e apresenta os resultados em um dashboard interativo.

ğŸ›  Funcionalidades
Coleta de Dados Automatizada:
Utiliza tÃ©cnicas de webscraping para extrair informaÃ§Ãµes de produtos, como:

Marca;
PreÃ§o;
AvaliaÃ§Ãµes e outros dados relevantes.
AnÃ¡lise de Dados:
GeraÃ§Ã£o de insights a partir dos dados coletados, como:

NÃºmero total de itens coletados;
NÃºmero de marcas Ãºnicas;
PreÃ§o mÃ©dio dos produtos;
SatisfaÃ§Ã£o por marca (baseada em avaliaÃ§Ãµes).
VisualizaÃ§Ã£o Interativa:
Dashboard dinÃ¢mico desenvolvido com Streamlit, que apresenta:

KPIs principais;
GrÃ¡ficos de barras;
Tabelas detalhadas.
Armazenamento Estruturado:
Os dados extraÃ­dos sÃ£o armazenados em um banco de dados SQLite, garantindo persistÃªncia e fÃ¡cil reuso.

ğŸ¯ Objetivo
Este projeto demonstra como tÃ©cnicas de webscraping podem ser combinadas com ferramentas de anÃ¡lise de dados para fornecer insights estratÃ©gicos. Ele Ã© Ãºtil para empresas e pesquisadores que desejam entender melhor o mercado de um produto especÃ­fico.

ğŸš€ Tecnologias Utilizadas
Python: Linguagem base do projeto;
Scrapy: Framework para web scraping;
SQLite: Banco de dados para armazenamento dos dados coletados;
pandas: Processamento e manipulaÃ§Ã£o de dados;
Streamlit: CriaÃ§Ã£o de dashboard interativo.

ğŸ“‚ Estrutura do Projeto

````pl
projectwebscraping/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ app.py  # AplicaÃ§Ã£o Streamlit
â”‚   â””â”€â”€ transformacao/
â”‚       â””â”€â”€ main.py  # Scripts de manipulaÃ§Ã£o dos dados
â”œâ”€â”€ data/
â”‚   â””â”€â”€ quotes.db  # Banco de dados SQLite com os dados extraÃ­dos
â””â”€â”€ README.md       # DocumentaÃ§Ã£o do projeto
````

ğŸ“ˆ Como Executar
1. Rodar o Web Scraping
Para coletar os dados diretamente do marketplace, execute o comando abaixo na pasta onde o Scrapy estÃ¡ configurado:

````bash
scrapy crawl mercadolivre -o ../../data/data.jsonl
````
Os dados serÃ£o salvos no arquivo data.jsonl, localizado na pasta data/.

2. Processar os Dados com Pandas
ApÃ³s a coleta, vocÃª pode processar os dados com Pandas. Execute este comando dentro da pasta src:

````bash
python transformacao/main.py
````
3. Executar o Dashboard Interativo
Para visualizar os insights, rode o Streamlit para carregar o dashboard:

````bash
streamlit run src/dashboard/app.py
````

ğŸ“ LicenÃ§a
Este projeto Ã© de cÃ³digo aberto e estÃ¡ licenciado sob os termos da MIT License.